{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://kaggle2.blob.core.windows.net/competitions/kaggle/4654/logos/front_page.png\"/>\n",
    "# <span style=\"color:blue;text-align:center;\">Trip Type Classification: v3 Baeysian Model</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walmart uses both art and science to continually make progress on their core mission of better understanding and serving their customers. One way Walmart is able to improve customers' shopping experiences is by segmenting their store visits into different trip types.\n",
    "<img src=\"https://kaggle2.blob.core.windows.net/competitions/kaggle/4654/media/walmart_triptypes640.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Base.String is deprecated, use AbstractString instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/modeltune.jl:5\n",
      "WARNING: Base.String is deprecated, use AbstractString instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/modeltune.jl:5\n",
      "WARNING: Base.String is deprecated, use AbstractString instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/modeltune.jl:5\n",
      "WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/deprecated/datapre.jl:104\n",
      "WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/deprecated/datapre.jl:105\n",
      "WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/deprecated/datapre.jl:163\n",
      "WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/deprecated/datapre.jl:163\n",
      "WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.\n",
      "  likely near /Users/diego/.julia/v0.4/MLBase/src/deprecated/datapre.jl:163\n"
     ]
    }
   ],
   "source": [
    "using DataFrames\n",
    "using MLBase\n",
    "using Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = readtable(\"data/train_shallow_featured.tsv\", separator='\\t')\n",
    "test = readtable(\"data/test_shallow_featured.tsv\", separator='\\t')\n",
    "full = vcat(train, test)\n",
    "\n",
    "original_full = vcat(readtable(\"data/train.csv.gz\"), readtable(\"data/test.csv.gz\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_features = [:TripType, :Weekday, :Upc, :DepartmentDescription, :FinelineNumber];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: deprecated syntax \"{a=>b for (a,b) in c}\" at In[4]:1.\n",
      "Use \"Dict{Any,Any}([a=>b for (a,b) in c])\" instead.\n"
     ]
    }
   ],
   "source": [
    "labels = Dict({column => labelmap(convert(Array, dropna(full[column]))) for column in categorical_features});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train[:, :]\n",
    "test = test[:, :];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [:Weekday, :Upc, :ScanCount, :DepartmentDescription, :FinelineNumber]\n",
    "label = :TripType;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split_train_val (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function split_train_val(df; train_size=.85, random_state=1)\n",
    "    srand(random_state)\n",
    "    nrows = size(df, 1)\n",
    "    indexes = shuffle(collect(1:nrows))\n",
    "    train = df[indexes[1:round(Int, nrows*train_size)], :]\n",
    "    validation = df[indexes[(round(Int, nrows*train_size)+1):end], :] \n",
    "    return train, validation\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_upc = Set{Int32}(full[:Upc])\n",
    "all_fineline_number = Set{Int32}(full[:FinelineNumber])\n",
    "all_trip_type = convert(Array{Int16, 1}, sort(collect(Set(dropna(original_full[:TripType])))));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val = split_train_val(train, train_size=.85, random_state=1)\n",
    "X_test = test\n",
    "\n",
    "sort!(X_train, cols=[:VisitNumber])\n",
    "sort!(X_val, cols=[:VisitNumber])\n",
    "sort!(X_test, cols=[:VisitNumber]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type BayesianModel{S <: AbstractString, T <: Real}\n",
    "    instances::Dict{S, Array{T, 1}}\n",
    "    prob_class::Dict{S, Array{T, 1}}\n",
    "    \n",
    "    column::Symbol\n",
    "    all_values::Set{Int32}\n",
    "    \n",
    "    BayesianModel(instances, prob_class, column, all_values) = new(instances, prob_class, column, all_values)\n",
    "    BayesianModel(column, all_values) = new(Dict{S, Array{T, 1}}(), Dict{S, Array{T, 1}}(), column, all_values)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculate_distance_matrix (generic function with 1 method)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training Functions\n",
    "\"\"\"\n",
    "function fit_bayesian(df, column, all_values)\n",
    "\n",
    "    model = BayesianModel{AbstractString, Float64}(column, all_values)\n",
    "\n",
    "    for subdf in groupby(df, :VisitNumber)\n",
    "\n",
    "        products = Dict{Int32, Float64}()\n",
    "        products_found = Set{Int32}()\n",
    "        trip_type_distribution = fill(0.0, length(all_trip_type)) \n",
    "\n",
    "        for i = 1:size(subdf, 1)\n",
    "\n",
    "            product, scan_count = subdf[i, model.column], subdf[i, :ScanCount]\n",
    "            products[product] = score_scan_count(scan_count)\n",
    "            scan_count != 0 && push!(products_found, product)\n",
    "\n",
    "            trip_type_distribution[subdf[i, :TripType]] += 1.0\n",
    "        end\n",
    "\n",
    "        key = create_key_from_products(products_found)\n",
    "        if !haskey(model.instances, key)\n",
    "            model.instances[key] = fill(0.0, length(model.all_values))\n",
    "            model.prob_class[key] = fill(0.0, length(all_trip_type))\n",
    "        end\n",
    "\n",
    "        model.instances[key] += [get(products, value, 0.0) for value in model.all_values]\n",
    "        model.prob_class[key] += trip_type_distribution\n",
    "    end\n",
    "    \n",
    "    for key in keys(model.prob_class)\n",
    "        model.prob_class[key] ./= sum(model.prob_class[key])\n",
    "    end\n",
    "\n",
    "    return model\n",
    "end\n",
    "\n",
    "create_key_from_products(products) = AbstractString(sort(collect(products)))\n",
    "\n",
    "\"\"\"\n",
    "Prediction Functions\n",
    "\"\"\"\n",
    "function predict_bayesian(fitted_model, to_predict_data, k=5)\n",
    "    \n",
    "    predicted_data = Array[]\n",
    "    \n",
    "    for subdf in groupby(to_predict_data, :VisitNumber)\n",
    "        instance = get_instance(subdf, fitted_model.column, fitted_model.all_values)\n",
    "        averaged_prob_classes = fill(0.0, length(all_tr))\n",
    "        # averaged_prob_classes = get_averaged_prob_classes_similar_instances(fitted_model.instances, \n",
    "        #                                                                    fitted_model.prob_class, \n",
    "        #                                                                    instance, k)\n",
    "        push!(predicted_data, vcat(subdf[1, :VisitNumber], averaged_prob_classes))\n",
    "    end\n",
    "    \n",
    "    predicted_df = predicted_data_to_dataframe(predicted_data)\n",
    "    \n",
    "    return predicted_df\n",
    "end\n",
    "\n",
    "function predict_bayesian(fitted_model, to_predict_data, k=5)\n",
    "    \n",
    "    predicted_data = Array{Float64}[]\n",
    "    \n",
    "    for subdf in groupby(to_predict_data, :VisitNumber)\n",
    "        key, instance = get_instance(subdf, fitted_model.column, fitted_model.all_values)\n",
    "        if haskey(fitted_model.prob_class, key)\n",
    "            averaged_prob_classes = fitted_model.prob_class[key]\n",
    "        else\n",
    "            # averaged_prob_classes = fill(0.0, length(all_trip_type))\n",
    "            averaged_prob_classes = get_averaged_prob_classes_similar_instances(fitted_model.instances, \n",
    "                                                                            fitted_model.prob_class, \n",
    "                                                                            instance, k)\n",
    "        end\n",
    "        \n",
    "        push!(predicted_data, vcat(subdf[1, :VisitNumber], averaged_prob_classes))\n",
    "    end\n",
    "    \n",
    "    predicted_df = predicted_data_to_dataframe(predicted_data)\n",
    "    \n",
    "    return predicted_df\n",
    "end\n",
    "\n",
    "function get_instance(df, column, all_values)\n",
    "    \n",
    "    products = Dict{Int32, Float64}()\n",
    "    products_found = Set{Int32}()\n",
    "\n",
    "    for i = 1:size(df, 1)\n",
    "        product, scan_count = df[i, column], df[i, :ScanCount]\n",
    "        products[product] = score_scan_count(scan_count)\n",
    "        scan_count != 0 && push!(products_found, product)\n",
    "    end\n",
    "\n",
    "    return create_key_from_products(products_found), \n",
    "           [get(products, value, 0.0) for value in all_values]\n",
    "end\n",
    "\n",
    "score_scan_count(value) = value < 0? log(2) : ( value == 0? 0 : log(value + 1) )\n",
    "# score_scan_count(value) = value < 0? 1 : ( value == 0? 0 : (value + 1) )\n",
    "\n",
    "function get_averaged_prob_classes_similar_instances(instances, prob_class, instance, k)\n",
    "    \n",
    "    top_similars = get_similars(instances, instance, k)\n",
    "    selected_prob_classes = Array[prob_class[last(tuple)] for tuple in top_similars]\n",
    "    \n",
    "    nrows, ncols = size(selected_prob_classes, 1), size(selected_prob_classes[1], 1)\n",
    "    selected_prob_classes = reshape(vcat(selected_prob_classes'...), (nrows, ncols))\n",
    "    \n",
    "    averaged_prob_class_values = [sum(selected_prob_classes[:, i])/nrows for i = 1:ncols]\n",
    "    \n",
    "    return averaged_prob_class_values\n",
    "end\n",
    "\n",
    "function get_similars(instances, instance, k)\n",
    "    similars = [(cosine_dist(instances[key], instance), key) for key in keys(instances)]\n",
    "    return sort(similars, rev=true)[1:k]\n",
    "end\n",
    "\n",
    "function predicted_data_to_dataframe(predicted_data)\n",
    "    \n",
    "    nrows, ncols = size(predicted_data, 1), size(predicted_data[1], 1)\n",
    "    predicted_data = reshape(vcat(predicted_data'...), (nrows, ncols))\n",
    "    predicted_df = convert(DataFrame, predicted_data)\n",
    "    names!(predicted_df, vcat(:VisitNumber, map(k -> symbol(\"TripType_$(round(Int, k))\"), all_trip_type)))\n",
    "    \n",
    "    return predicted_df\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263.107127 seconds (15.05 M allocations: 10.713 GB, 9.06% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time train_model = fit_bayesian(X_train, :FinelineNumber, all_fineline_number);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 214"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "LoadError: InterruptException:\nwhile loading In[66], in expression starting on line 2",
     "output_type": "error",
     "traceback": [
      "LoadError: InterruptException:\nwhile loading In[66], in expression starting on line 2",
      "",
      " in sort! at sort.jl:222",
      " in sort! at sort.jl:310",
      " in sort! at sort.jl:315 (repeats 3 times)",
      " in sort! at sort.jl:316 (repeats 4 times)",
      " in sort! at sort.jl:315",
      " in sort! at sort.jl:316",
      " in sort! at sort.jl:315 (repeats 2 times)",
      " in sort! at sort.jl:316",
      " in sort! at sort.jl:402",
      " in sort at sort.jl:413",
      " in get_similars at In[64]:119",
      " in get_averaged_prob_classes_similar_instances at In[64]:106",
      " in predict_bayesian at In[64]:73"
     ]
    }
   ],
   "source": [
    "tic(); predicted_train = predict_bayesian(train_model, X_train, 5); toc();\n",
    "tic(); predicted_val = predict_bayesian(train_model, X_val, 5); toc();\n",
    "tic(); predicted_test = predict_bayesian(train_model, X_test, 5); toc();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Evaluate by **Accuracy (Acc)**: $\\frac{TP+TN}{TP+FP+FN+TN}$\n",
    "2. Evaluate by **Multi-Class Logarithmic Loss (MCLL)**: $-1\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{j=1}^{M}\\delta_{ij}log(p_{ij})$  \n",
    "    where N is the number of visits, M is the number of trip type, $y_{ij}$ is the [Kroneckler Delta](https://en.wikipedia.org/wiki/Kronecker_delta) when the observations exists in test file and $p_{ij}$ is the corresponding prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_mcll (generic function with 1 method)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function create_visit_number_dict(groundtruth)\n",
    "    visit_number_dict = Dict{Int64, Set{Int64}}()\n",
    "    for i = 1:size(groundtruth, 1)\n",
    "        visit_number = groundtruth[i, :VisitNumber]\n",
    "        if !haskey(visit_number_dict, visit_number)\n",
    "            visit_number_dict[visit_number] = Set{Int64}()\n",
    "        end\n",
    "        push!(visit_number_dict[visit_number], groundtruth[i, label])\n",
    "    end\n",
    "    \n",
    "    return visit_number_dict\n",
    "end\n",
    "\n",
    "function eval_mcll(groundtruth, df)\n",
    "    vn_dict = create_visit_number_dict(groundtruth)\n",
    "    \n",
    "    epsilon = 1e-15\n",
    "    total_score_v1 = 0\n",
    "    total_score_v2 = 0\n",
    "\n",
    "    N, M = size(df)\n",
    "    \n",
    "    for i = 1:N, j = 2:M\n",
    "        visit_number = df[i, :VisitNumber]\n",
    "        trip_type = all_trip_type[j-1]\n",
    "        yhat = df[i, j]\n",
    "        in_gt = trip_type in vn_dict[visit_number]? 1 : 0\n",
    "        total_score_v1 += in_gt == 1? max(min(log(yhat), 1-epsilon), epsilon) : 0\n",
    "        total_score_v2 += in_gt * yhat\n",
    "    end\n",
    "    \n",
    "    return -1/N * total_score_v1, total_score_v2 / N\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCLLv1 - Score-Train: -6.699462068819703e-16\tScore-Val: 0\n",
      "MCLLv2 - Score-Train: 0.0006019549557655793\tScore-Val: 0\n"
     ]
    }
   ],
   "source": [
    "eval_mcll_train_v1, eval_mcll_train_v2 = eval_mcll(X_train, predicted_train) \n",
    "#eval_mcll_val_v1, eval_mcll_val_v2 = eval_mcll(X_val, predicted_val)\n",
    "eval_mcll_val_v1, eval_mcll_val_v2 = 0, 0\n",
    "println(\"MCLLv1 - Score-Train: $eval_mcll_train_v1\\tScore-Val: $eval_mcll_val_v1\")\n",
    "println(\"MCLLv2 - Score-Train: $eval_mcll_train_v2\\tScore-Val: $eval_mcll_val_v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Submission Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writetable(\"data/submission_v1_bayesian_model.csv\", predicted_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Predictions to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v1 Raw Attr. + H. Miss. + Bayesian Model **33.60892** (MCLL-T: 0.040 MCLL-V: 0.082)  \n",
    "v1 Raw Attr. + H. Miss. + XGBoost **31.74538** (Acc-T: .06 Score-Val: .03 MCLL-T: .2813 MCLL-V: .025)  \n",
    "v1.1 Raw Attr. + H. Miss. + RF(RFeat5, Trees100, Subs.5) + All Data **33.57726** (Acc-Train: .11\tAcc-Val: .07, MCLL-Train: .353 MCLL-Val: .079)  \n",
    "v1 Raw Attr. + H. Miss. + RF(RFeat5, Trees100, Subs.5) + SubSample **34.13327** (Acc - Score-Train: 0.32\tScore-Val: 0.15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.1-pre",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
